{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "print(sagemaker.__version__)\n",
    " \n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = session.default_bucket()\n",
    "\n",
    "prefix = 'pascalvoc'\n",
    "\n",
    "s3_train_data = 's3://{}/{}/input/train'.format(bucket, prefix)\n",
    "s3_validation_data = 's3://{}/{}/input/validation'.format(bucket, prefix)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "print(s3_train_data)\n",
    "print(s3_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.TrainingInput(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix',\n",
    "                        input_mode='Pipe')\n",
    "\n",
    "validation_data = sagemaker.TrainingInput(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix',\n",
    "                             input_mode='Pipe')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "\n",
    "region = boto3.Session().region_name    \n",
    "container = image_uris.retrieve('object-detection', region)\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "od = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.p3.2xlarge',\n",
    "                                   output_path=s3_output_location,\n",
    "                                   use_spot_instances=True,\n",
    "                                   max_run=7200,                    \n",
    "                                   max_wait=10800,\n",
    "                                   volume_size=1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.set_hyperparameters(base_network='resnet-50',\n",
    "                       use_pretrained_model=1,\n",
    "                       num_classes=20,\n",
    "                       epochs=30,\n",
    "                       num_training_samples=16551,\n",
    "                       mini_batch_size=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.001, 0.1, scaling_type='Logarithmic'), \n",
    "    'momentum': ContinuousParameter(0.8, 0.999), \n",
    "    'weight_decay': ContinuousParameter(0.0001, 0.001), \n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:mAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(od,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=30,\n",
    "                            max_parallel_jobs=2,\n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "exp = HyperparameterTuningJobAnalytics(\n",
    "    hyperparameter_tuning_job_name=tuner.latest_tuning_job.name\n",
    ")\n",
    "od_jobs = exp.dataframe()\n",
    "od_jobs.sort_values('FinalObjectiveValue', ascending=0)\n",
    "od_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_predictor = tuner.deploy(initial_instance_count = 1, instance_type = 'ml.c5.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O test.jpg https://upload.wikimedia.org/wikipedia/commons/6/67/Chin_Village.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "import numpy as np\n",
    "\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker')\n",
    "\n",
    "with open('test.jpg', 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=od_predictor.endpoint_name, \n",
    "                                   ContentType='image/jpeg', \n",
    "                                   Body=payload)\n",
    "\n",
    "response = response['Body'].read()\n",
    "response = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', \n",
    "                     'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "                     'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "threshold = 0.30\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection('test.jpg', response['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
