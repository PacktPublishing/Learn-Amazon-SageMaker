{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Marketing with Amazon SageMaker AutoPilot\n",
    "\n",
    "Last update: July 22nd, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "print (sagemaker.__version__)\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()                     \n",
    "prefix = 'sagemaker/DEMO-automl-dm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "wget -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "unzip -o bank-additional.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the CSV file into a Pandas data frame and take a look at the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "data = pd.read_csv('./bank-additional/bank-additional-full.csv')\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 50)         # Keep the output on one page\n",
    "data[:10] # Show the first 10 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # (number of lines, number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "We split the dataset into training (95%) and test (5%) datasets. We will use the training dataset for AutoML, where it will be automatically split again for training and validation.\n",
    " \n",
    "Once the model has been deployed, we'll use the test dataset to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to 123 for reproductibility\n",
    "# https://pandas.pydata.org/pandas-docs/version/0.25/generated/pandas.DataFrame.sample.html\n",
    "# https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html\n",
    "train_data, test_data, _ = np.split(data.sample(frac=1, random_state=123), \n",
    "                                                  [int(0.95 * len(data)), int(len(data))])  \n",
    "\n",
    "# Save to CSV files\n",
    "train_data.to_csv('automl-train.csv', index=False, header=True) # Need to keep column names\n",
    "test_data.to_csv('automl-test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l automl*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No preprocessing needed!** AutoML will take care of this, so let's just copy the training set to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_data = sess.upload_data(path=\"automl-train.csv\", key_prefix=prefix + \"/input\")\n",
    "print(s3_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the SageMaker AutoPilot job\n",
    "\n",
    "After uploading the dataset to S3, we can invoke SageMaker AutoPilot to find the best ML pipeline to train a model on this dataset. \n",
    "\n",
    "The required inputs for invoking a SageMaker AutoML job are the dataset location in S3, the name of the column of the dataset you want to predict (`y` in this case) and an IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.automl.automl import AutoML\n",
    "# https://sagemaker.readthedocs.io/en/stable/automl.html\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "auto_ml_job = AutoML(\n",
    "    role = role,                                              # IAM permissions for SageMaker\n",
    "    sagemaker_session = sess,                                 # \n",
    "    target_attribute_name = 'y',                              # The column we want to predict\n",
    "    output_path = 's3://{}/{}/output'.format(bucket,prefix),  # Save artifacts here\n",
    "    max_runtime_per_training_job_in_seconds = 600,\n",
    "    max_candidates = 500,\n",
    "    total_job_runtime_in_seconds = 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SageMaker AutoPilot job\n",
    "\n",
    "We can now launch the job by calling the `fit()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_job.fit(inputs=s3_input_data, logs=False, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_job.describe_auto_ml_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking the progress of the AutoPilot job\n",
    "SageMaker AutoPilot job consists of four high-level steps : \n",
    "* Data Preprocessing, where the dataset is split into train and validation sets.\n",
    "* Recommending Pipelines, where the dataset is analyzed and SageMaker AutoPilot comes up with a list of ML pipelines that should be tried out on the dataset.\n",
    "* Automatic Feature Engineering, where SageMaker AutoPilot performs feature transformation on individual features of the dataset as well as at an aggregate level.\n",
    "* ML pipeline selection and hyperparameter tuning, where the top performing pipeline is selected along with the optimal hyperparameters for the training algorithm (the last stage of the pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "job = auto_ml_job.describe_auto_ml_job()\n",
    "job_status = job['AutoMLJobStatus']\n",
    "job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "\n",
    "if job_status not in ('Stopped', 'Failed'):\n",
    "    while job_status in ('InProgress') and job_sec_status in ('AnalyzingData'):\n",
    "        sleep(30)\n",
    "        job = auto_ml_job.describe_auto_ml_job()\n",
    "        job_status = job['AutoMLJobStatus']\n",
    "        job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "        print (job_status, job_sec_status)\n",
    "    print(\"Data analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing notebooks generated by SageMaker AutoPilot\n",
    "Once data analysis is complete, SageMaker AutoPilot generates two notebooks: \n",
    "* Data exploration,\n",
    "* Candidate definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = auto_ml_job.describe_auto_ml_job()\n",
    "job_candidate_notebook = job['AutoMLJobArtifacts']['CandidateDefinitionNotebookLocation']\n",
    "job_data_notebook = job['AutoMLJobArtifacts']['DataExplorationNotebookLocation']\n",
    "\n",
    "print(job_candidate_notebook)\n",
    "print(job_data_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy these two notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s $job_candidate_notebook $job_data_notebook\n",
    "aws s3 cp $1 .\n",
    "aws s3 cp $2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to the folder view, and open these notebooks. Lots of useful information in there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker AutoPilot then launches feature engineering, and prepares different training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = auto_ml_job.describe_auto_ml_job()\n",
    "job_status = job['AutoMLJobStatus']\n",
    "job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "\n",
    "if job_status not in ('Stopped', 'Failed'):\n",
    "    while job_status in ('InProgress') and job_sec_status in ('FeatureEngineering'):\n",
    "        sleep(30)\n",
    "        job = auto_ml_job.describe_auto_ml_job()\n",
    "        job_status = job['AutoMLJobStatus']\n",
    "        job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "        print (job_status, job_sec_status)\n",
    "    print(\"Feature engineering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once feature engineering is complete, SageMaker AutoPilot launches Automatic Model Tuning on the different candidates. While model tuning is running, we can explore its progress with SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "exp = ExperimentAnalytics(\n",
    "    sagemaker_session=sess, \n",
    "    experiment_name=job['AutoMLJobName'] + '-aws-auto-ml-job'\n",
    ")\n",
    "\n",
    "df = exp.dataframe()\n",
    "print(\"Number of jobs: \", len(df))\n",
    "\n",
    "# Move metric to first column\n",
    "df = pd.concat([df['ObjectiveMetric - Max'], df.drop(['ObjectiveMetric - Max'], axis=1)], axis=1)\n",
    "# Show top 5 jobs\n",
    "df.sort_values('ObjectiveMetric - Max', ascending=0)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = auto_ml_job.describe_auto_ml_job()\n",
    "job_status = job['AutoMLJobStatus']\n",
    "job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "\n",
    "if job_status not in ('Stopped', 'Failed'):\n",
    "    while job_status in ('InProgress') and job_sec_status in ('ModelTuning'):\n",
    "        sleep(30)\n",
    "        job = auto_ml_job.describe_auto_ml_job()\n",
    "        job_status = job['AutoMLJobStatus']\n",
    "        job_sec_status = job['AutoMLJobSecondaryStatus']\n",
    "        print (job_status, job_sec_status)\n",
    "    print(\"Model tuning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the best candidate\n",
    "Now that we have successfully completed the AutoML job on our dataset and visualized the trials, we can create a model from any of the trials with a single API call and then deploy that model for online or batch prediction using [Inference Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html). For this notebook, we deploy only the best performing trial for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best candidate is the one we're really interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_best_candidate = auto_ml_job.best_candidate()\n",
    "print(job_best_candidate['CandidateName'])\n",
    "print(job_best_candidate['FinalAutoMLJobObjectiveMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, gmtime\n",
    "timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "endpoint_name = job['AutoMLJobName']+'-'+timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_job.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    endpoint_name = endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the best candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict and score the validation set. We'll compute metrics ourselves just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sess, \n",
    "    content_type=CONTENT_TYPE_CSV, \n",
    "    accept='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "tp = tn = fp = fn = count = 0\n",
    "\n",
    "with open('automl-test.csv') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines[1:]:   # Skip header\n",
    "        l = l.split(',')  # Split CSV line into feature array\n",
    "        label = l[-1]     # Store 'yes'/'no' label\n",
    "        l = l[:-1]        # Remove label\n",
    "        l = ','.join(l)   # Rebuild CSV line without label\n",
    "                \n",
    "        response = predictor.predict(l)\n",
    "        response = response.decode(\"utf-8\")\n",
    "        #print (\"label %s response %s\" %(label,response))\n",
    "\n",
    "        if 'yes' in label:\n",
    "            # Sample is positive\n",
    "            if 'yes' in response:\n",
    "                # True positive\n",
    "                tp=tp+1\n",
    "            else:\n",
    "                # False negative\n",
    "                fn=fn+1\n",
    "        else:\n",
    "            # Sample is negative\n",
    "            if 'no' in response:\n",
    "                # True negative\n",
    "                tn=tn+1\n",
    "            else:\n",
    "                # False positive\n",
    "                fp=fp+1\n",
    "        count = count+1\n",
    "        if (count % 100 == 0):   \n",
    "            sys.stdout.write(str(count)+' ')\n",
    "            \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print (\"%d %d\" % (tn, fp))\n",
    "print (\"%d %d\" % (fn, tp))\n",
    "\n",
    "accuracy  = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall    = tp/(tp+fn)\n",
    "f1        = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print (\"%.4f %.4f %.4f %.4f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the endpoint\n",
    "Once that we're done predicting, we can delete the endpoint (and stop paying for it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SageMaker AutoML job creates many underlying artifacts such as dataset splits, preprocessing scripts, preprocessed data, etc. Let's delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "job_outputs_prefix = '{}/output/{}'.format(prefix, job['AutoMLJobName'])\n",
    "print(job_outputs_prefix)\n",
    "\n",
    "s3_bucket =boto3.resource('s3').Bucket(bucket)\n",
    "s3_bucket.objects.filter(Prefix=job_outputs_prefix).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
